# Home_Sales
## SparkSQL to determine key metrics about home sales data - Module 22 Challenge
Objective: Use SparkSQL to determine key metrics about home sales data. We will create temporary views, partition the data, cache and uncache a temporary table, and verify that the table has been uncached.


## Getting Started
Clone the repository and import PySpark SQL and other needed libraries. Open Home_Sales.ipynb notebook and run each cell sequentially. The notebook is designed to guide you through data loading, caching, partitioning, and creating temp tables.

Link: https://github.com/pandarik/Home_Sales/blob/main/Home_Sales.ipynb



## Acknowledgments
Leveraged Google, ChatGPT, and Copilot as/where needed to develop/validate/troubleshoot code/data/functions. The Python and data science community for their invaluable resources.
